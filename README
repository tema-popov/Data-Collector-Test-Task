Программа парсит обьявления Яндекс:работа по данному запросу и генерирует гипотезы кластеризации. 
Адрес веб странички localhost:8080/search.xml
Структура необходимой базы данных описана в ./sql
Запуск приложения выполняется по скрипту start.sh

Компоненты:

Job - Класс, описывающий запись базы данных 
ConfigMakerByQuery - Изменяет конфигурацию WebHarvester по данному запросу
Miner - с помощью WebHarvester парсится странички Я:Работа в xml файл с данными
Parser - перевод из спарсеного xml в List<Job>
Storekeeper - класс для работы с БД и создания различных запросов
Clusterizer - Класс, создающий гипотезы класстеризации

Кластеризация выполнена довольно наивным способом - Заголовок, Описание и Зарплата сравниаются
по одному способу: возьмём множеста слов длиной больше двух символов(чтобы исключить большинство предлогов, союзов, итп)
в обоих текстах и найдём их пересечение. отношение size(A пересечь с B)/max(size(A),size(b)) назовём коэфицентом похожести(КП)
тогда записи похожи, если |КП(Описание) * 0.45 + КП(Зарплата)* 0.2 + КП(заголовок) * 0.35 >= 0.75|
Сравниваем все записи между собой и выделяем кластеры. Алгоритм довольно медленный - работает за O(n^2),
но в условиях задачи вполне приемлемый.
Также можно было использовать в качестве структуры данных, на которой производится алгоритм, СНМ,
к сожалению реализовать это я не успел.
Полноту такого подхода достаточно сложно оценить, но я думаю, что она вполне приемлема,
если было найдено 210 дубликатов из 1460 записей, и это ещё учитывая кластеризацию Яндекса. 
Глазами было найдено около 10 ошибок, так что точность тоже довольно приемлима для такого примитивного подхода

Ответ на контрольный тест лежит ./tests 
